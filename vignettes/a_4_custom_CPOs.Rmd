---
title: "Building Custom CPOs"
author: "Martin Binder"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{4. Custom CPOs}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r, eval = TRUE, child = 'toc/vignettetoc.Rmd'}
```

```{r, echo = FALSE}
library("mlrCPO")
```

## Intro

The [`CPO`s built into `mlrCPO`](a_3_all_CPOs.html) can be used for many different purposes, and can be combined to form even more powerful transformation operations. However, in some cases, it may be necessary to define new "custom" `CPO`s that perform a certain task; either because a preprocessing method is not (yet) defined as a builtin `CPO`, or because some operation very specific to the task at hand needs to be performed.

For this purpose, `mlrCPO` offers a very powerful interface for the creation of new `CPO`s. The functions and methods described here are also the methods used internally to create `mlrCPO`'s builtin `CPO`s. Therefore, to learn the art of defining `CPO`s, it is also possible to look at the [`mlrCPO` source tree](https://github.com/mlr-org/mlrCPO/tree/master/R) in files starting with "`CPO_`" for example `CPO` definitions.

There are three types of `CPO`: "Feature Operation `CPO`s" (**FOCPO**s) which are only allowed to change feature columns of incoming data, and which are the most common `CPO`s; "Target Operation `CPO`s" (**TOCPO**s) that change only target columns, and "Retrafoless `CPO`s" (**ROCPO**s) that may add or delete rows to a data set, but only during training. Conceptually, ROCPOs are the simplest `CPO`s, followed by FOCPOs and the even more complicated TOCPOs. The commonalities of all `CPO` defining functions will be described first, followed by the different `CPO` types in order of growing complexity.

## Making a CPO

To create a `CPOConstructor` that can then be used to create a `CPO`, a `makeCPO*()` function needs to be called. There are five functions of this kind, differing by what kind of `CPO` they create and how much flexibility (at the cost of simplicity) they offer the user:

| `CPO` type | `makeCPO*()` functions |
|----|-----------|
| FOCPO | `makeCPO()`, `makeCPOExtendedTrafo()` |
| TOCPO | `makeCPOTargetOp()`, `makeCPOExtendedTargetOp()` |
| ROCPO | `makeCPORetrafoless()` |

Each of these functions takes a "name" for the new `CPO`, settings for the parameter set to be used, settings for the format in which the data is supposed to be provided, data property settings, the packages to load, `CPO` type specific settins, and finally the transformation functions.

### CPO name

Each `CPO` has a "name" that is used for representation when printing, and as the default prefix for hyperparameters. `cpoPca`, for example, has the name "`pca`":
```{r}
!cpoPca()
```
The name is set using the `cpo.name` parameter of the `make*()` functions.

### CPO parameters

The `ParSet` used by the `CPO` are given as the second `par.set` parameter. These parameters must be either constructed using `makeParamSet()` from the `ParamHelpers` package, or using the `pSS()` function for a more concise `ParSet` definition. The given parameters will then be the function parameters of the `CPOConstructor`, and will by default be exported as hyperparameters (prefixed with the `cpo.name`).

It is possible to use the default parameter values of the `par.set` as defaults, or to give a `par.vals` list of default values. If `par.vals` is given, the defaults within `par.set` are completely ignored. Parameters that have a default value are set to this value upon construction if no value is given by the user.

Not all available parameters of a `CPO` need to be exported as hyperparameters. *Which* parameters are exported can be set during `CPO` construction, but the default exported parameters can be set using `export.params`. This can either be a `character` vector of the names of parameters to export, or `TRUE` (default, export all) or `FALSE` (no export).

### Data Format

Different `CPO` operations may want to operate on the data in different forms: as a `Task`, as a `data.frame` with or without the target column, etc. The `CPO` framework can perform some conversion of data to fit different needs, which is set up by the value of the `dataformat` parameter, together with `dataformat.factor.with.ordered`. While `dataformat` has slightly different effects on different `CPO` types, typically its values and effects are:

| `dataformat` | Effect |
|------------|--------------------------------------------------------------------|
| `"task"` | Data is given as a `Task`; if the data to be transformed is a `data.frame`, it is converted to a `cluster` task before handing it to the transformation functions.
| `"df.all"` | Data is given as a `data.frame`, with the target column included. |
| `"df.features"` | Data is given as a `data.frame`, the target is given as a separate `data.frame`. |
| `"split"` | Data is given as a named list with slots `$numeric`, `$factor`, `$ordered`, `$other`, each of which contains a `data.frame` with the columns of the respective type. If `dataformat.factor.with.ordered` is `TRUE`, the `$ordered` slot is not present, and ordered features are instead given to `$factor` as well. Features that are not any of these types are given to `"other"`. The target is given as a separate `data.frame`. |
| `"factor"`, `"ordered"`, `"numeric"` | Only the data from columns of the named type are given to the transformatin functions as a `data.frame`. The target columns are given as a separate `data.frame`. |

Another parameter influencing the data format is the `fix.factors` flag which controls whether factor levels of prediction data need to be set to be the same as during training. If it is `TRUE`, previously unseen factor levels are set to `NA` during prediction.

### Properties

`mlr` and `mlrCPO` make it possible to specify what kind of data a `CPO` or a `Learner` can handle. However, since `CPO`s may change data to be more or less fitting for a certain `Learner`, a `CPO` must announce not only what data it can handle, but also how it changes the capabilities of the machine learning pipeline in which it is envolved. During construction, four parameters related to properties can be given.

The `properties.data` parameter defines what properties of feature data the `CPO` can handle; it must be a subset of `"numerics"`, `"factors"`, `"ordered"`, and `"missings"`. Typically, only the `"missings"` part is interesting since `CPO`s that only handle a subset of types will usually just ignore columns of other types.

The `properties.target` parameter defines what `Task` properties related to the task type and the target column a `CPO` can handle. It is a subset of `"cluster"`, `"classif"`, `"multilabel"`, `"regr"`, `"surv"` (so far defining the task type a `CPO` can handle), `"oneclass"`, `"twoclass"`, `"multiclass"` (properties specific to `classif` `Task`s). Most FOCPOs do not care about the task type, while TOCPOs may only support a single task type.

`properties.adding` lists the properties that a CPO *adds* to the capabilities of a machine learning pipeline when it is executed before it, while `properties.needed` lists the properties *needed* from the following pipeline. `cpoDummyEncode`, for example, a `CPO` that converts factors and ordereds to numerics, has `properties.adding == c("factors", "ordered")` and `properties.needed == "numerics"`. The many imputation `CPO`s have `properties.adding == "missings"`. Usually these are only a subset of the possible `properties.data` states, but for TOCPOs this may also be any of `"oneclass"`, `"twoclass"`, `"multiclass"`. Note that neither `properties.adding` nor `properties.needed` may be any task type, even for TOCPOs that perform task conversion.

#### Property Checking and `.sometimes` Properties

The `CPO` framework will check that a `CPO` only adds and removes the kind of data properties that it declared in `properties.adding` and `properties.needed`. It will also check that composition of `CPO`s, and attachment of `CPO`s to `Learner`s, work out. Sometimes, however, it is necessary to treat a `CPO` like it does a certain manipulation (removing `missings`, for example) in some cases, while not in others. A `CPO` that only imputes missings in *numeric* columns should be treated as `properties.adding == "missings"` when is is attached to a `Learner`, and the `Learner` should gain the `"missings"` property. However, when data that has missings in its factorial columns is given to this `CPO`, the `CPO` framework will complain that the `CPO` that declared `"missings"` in `properties.adding` returned data that still had missing values in it. The solution to this dilemma is to suffix some properties with "`.sometimes`" when declaring them in `properties.adding` and `properties.needed`. When composing `CPO`s, and when checking data *returned* by a `CPO`, the framework will then be as lenient as possible. In the given example, `properties.adding == "missings"` will be assumed when attaching the `CPO` to a `Learner`, while `properties.adding == character(0)` is assumed when checking the `CPO`'s output (and missing values that were not imputed are therefore forgiven).

### Packages

The single `packages` parameter can be set to a `character` vector listing packages necessary for a `CPO` to work. This is mostly useful when a `CPO` should be defined as part of a package or script to be distributed. The listed package will *not* automatically be *attached*, it will only be *loaded*. This means that a function exported by a package still needs to be called using `::`. The benefit of declaring it in `packages` is that it will be loaded upon *construction* of a `CPO`, which means that a user will get immediate feedback about whether the `CPO` can be used or needs more packages to be installed.

### Transformation Functions

The different types of `CPO`, and the different `make*()` functions, need different transformation functions to be defined. The principle behind these functions is alwasy the same, however: The `CPO` framework takes input data, transforms it according to `dataformat`, checks it according to `properties.data` and `properties.target`, and then gives it to one or more user-given transformation function. The transformation function must then usually create a control object containing information about the data to be used later, or transform the incoming data and return the transformation result (or both). The `CPO` framework then checks the transformed data according to `properties.adding` and `properties.needed` and gives it back to the `CPO` user.

Transformation functions are given to parameters starting with `cpo.`. They can either be given as functions, or as "**headless**" functions missing the `function(...)` part. In the latter case, the headless function must be a succession of expressions enclosed in curly braces (`{`, `}`) and the necessary function head is added by the `CPO` framework. The functions often take a subset of `data`, `target`, `control`, or `control.invert` parameters, in addition to all parameters as given in `par.set`.

#### Functional Transformation

The communication between transformation functions, e.g. giving the PCA matrix to its retrafo function, usually happens via "control" objects created by these functions and then given as parameter to other functions. In some cases, however, it may be more elegant to create a new function (e.g. a `cpo.retrafo` function) within another function as a "closure" (in the general, not R specific, sense) with access to all the outer functions variables. The `CPO` framework makes this possible by allowing a function to be given instead of a "control" object. The function which would usually receive this control object must then be given as `NULL` in the `makeCPO*()` call.

## Retrafoless CPOs

Retrafoless `CPO`s, or ROCPOs, are conceptually the simplest `CPO` type, since they do not create `CPOTrained` objects and therefore only need one transformation function: `cpo.trafo`. The value of the `dataformat` parameter may only be either `"df.all"` or `"task"`, resulting in either a `data.frame` (consisting all columns, including the target column) or a `Task` being given to the `cpo.trafo` function. `cpo.trafo` should have the parameters `data` (receiving the data as either a `Task` or `data.frame`), `target` (receiving the names of target columns in the data), and any parameter as given to `par.set`. The return value of `cpo.trafo` must be the transformed data, in the same format (`data.frame` or `Task`) as given as input.

Since a ROCPO only transforms incoming data during training, it should not do any transformation of target or feature values that would make it necessary to repeat this action during prediction. It may, for example, be used for subsampling a classification task to balance target classes, but it should not change the levels or values of given data rows.

The following is an example of a simplified version of the `cpoSample` `CPO`, which takes one parameter `fraction` and then subsamples a `fraction` part of incoming data without replacement:
```{r}
xmpSample = makeCPORetrafoless("exsample",  # nolint
  pSS(fraction: numeric[0, 1]),
  dataformat = "df.all",
  cpo.trafo = function(data, target, fraction) {
    newsize = round(nrow(data) * fraction)
    row.indices = sample(nrow(data), newsize)
    data[row.indices, ]
  })

cpo = xmpSample(0.01)
```
```{r}
iris %>>% cpo
```

It is possible to give the `cpo.trafo` as **headless** transformation function by just leaving out the function header. This can save a lot of boilerplate code when there are many parameters present, or when many transformation functions need to be given. The resulting `CPO` is completely equivalent to the one given above.
```{r}
xmpSampleHeadless = makeCPORetrafoless("exsample",  # nolint
  pSS(fraction: numeric[0, 1]),
  dataformat = "df.all",
  cpo.trafo = {
    newsize = round(nrow(data) * fraction)
    row.indices = sample(nrow(data), newsize)
    data[row.indices, ]
  })
```

## Feature Operation CPOs


In principle, a `CPO` needs a function that "trains" a control object depending on the data (`cpo.trafo`),
and another function that uses this control object, and new data, to perform the preprocessing operation (`cpo.retrafo`).
The `cpo.trafo`-function must return a "control" object which contains all information about how to transform a given dataset.
`cpo.retrafo` takes a (potentially new!) dataset *and* the "control" object returned by `cpo.trafo`, and transforms the new data according to plan.
```{r}
names(formals(makeCPO))  # see help(makeCPO) for explanation of arguments
```

```{r}
constFeatRem = makeCPO("constFeatRem",  # nolint
  dataformat = "df.features",
  cpo.train = function(data, target) {
    names(Filter(function(x) {  # names of columns to keep
        length(unique(x)) > 1
      }, data))
    }, cpo.retrafo = function(data, control) {
    data[control]
  })
head(iris) %>>% constFeatRem()
print(constFeatRem, verbose = TRUE)
```


## Creating Custom CPOs
Custom CPOs can be created using the `makeCPO` function. Its most important arguments are `cpo.trafo` and `cpo.retrafo`, both of which are functions. The `cpo.trafo`-function must return a "control" object which contains all information about how to transform a given dataset. `cpo.retrafo` takes a (potentially new!) dataset *and* the "control" object returned by `cpo.trafo`, and transforms the new data according to plan.
```{r}
names(formals(makeCPO))  # see help(makeCPO) for explanation of arguments
```

```{r}
constFeatRem = makeCPO("constFeatRem",  # nolint
  dataformat = "df.features",
  cpo.train = function(data, target) {
    names(Filter(function(x) {  # names of columns to keep
        length(unique(x)) > 1
      }, data))
    }, cpo.retrafo = function(data, control) {
    data[control]
  })
head(iris) %>>% constFeatRem()
print(constFeatRem, verbose = TRUE)
```

It is also possible to set `cpo.retrafo = NULL`. Then `cpo.trafo` must return a function that takes a `data` argument, which is a (possibly new) dataset to transform, and returns the transformed data. The following example is equivalent to the example above:
```{r}
constFeatRem = makeCPO("constFeatRem",  # nolint
  dataformat = "df.features",
  cpo.train = function(data, target) {
    cols.keep = names(Filter(function(x) {
    length(unique(x)) > 1
      }, data))
    # the following function will do both the trafo and retrafo
    result = function(data) {
      data[cols.keep]
    }
    result
  }, cpo.retrafo = NULL)
head(iris) %>>% constFeatRem()
print(constFeatRem, verbose = TRUE)
```
