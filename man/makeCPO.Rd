% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/makeCPO.R
\name{makeCPO}
\alias{makeCPO}
\title{Create a custom CPO constructor}
\usage{
makeCPO(cpo.name, par.set = NULL, par.vals = list(),
  dataformat = c("df.features", "split", "df.all", "task", "factor",
  "ordered", "numeric"), dataformat.factor.with.ordered = TRUE,
  export.params = TRUE, fix.factors = FALSE, properties = c("numerics",
  "factors", "ordered", "missings"), properties.adding = character(0),
  properties.needed = character(0), properties.target = c("cluster",
  "classif", "multilabel", "regr", "surv", "oneclass", "twoclass",
  "multiclass"), packages = character(0), cpo.trafo, cpo.retrafo)
}
\arguments{
\item{cpo.name}{[\code{character(1)}]\cr
The name of the resulting CPO constructor / CPO. This is used for identification in output,
and as the default \code{id}.}

\item{par.set}{[\code{ParamSet} | \code{NULL}]\cr
Optional parameter set, for configuration of CPOs during construction or by hyperparameters.
Default is \code{NULL}.}

\item{par.vals}{[\code{list}]\cr
Named list of default parameter values for the CPO. These are used additionally to the
parameter default values in \code{par.set}. It is preferred to use
these default values, and not \code{par.vals}. Default is \code{list()}.}

\item{dataformat}{[\code{character(1)}]\cr
  Indicate what format the data should be as seen by \dQuote{cpo.trafo} and the retrafo function. Possibilities are:
  \tabular{lll}{
    \bold{dataformat} \tab \bold{data}               \tab \bold{target}         \cr
    df.all      \tab data.frame with target cols     \tab target colnames       \cr
    df.features \tab data.frame without target       \tab data.frame of target  \cr
    task        \tab full task                       \tab target colnames       \cr
    split       \tab list of data.frames by type     \tab data.frame of target  \cr
    [type]      \tab data.frame of [type] feats only \tab data.frame of target  \cr
  }
  [type] can be any one of \dQuote{factor}, \dQuote{numeric}, \dQuote{ordered}.\cr
  For \code{dataformat} \code{==} \dQuote{split}, the list has entries \dQuote{factor}, \dQuote{numeric},
  \dQuote{other}, and possibly \dQuote{ordered}--the last one only present if \code{dataformat.factor.with.ordered}
  is \code{FALSE}.

  If the CPO is a Feature Operation CPO, then the return value of the retrafo function must be in the same format as the one requested.
  E.g. if \code{dataformat} is \dQuote{split}, the return value must be a named list with entries \dQuote{numeric},
  \dQuote{factor}, and \dQuote{other}. The types of the returned data may be arbitrary: In the given example,
  the \dQuote{factor} slot of the returned list may contain numeric data. (Note however that if data is returned
  that has a type not already present in the data, \dQuote{properties.needed} must specify this.)

  If \code{dataformat} is either \dQuote{df.all} or \dQuote{task}, the
  target column(s) in the returned value of the retrafo function must be identical with the target column(s) given as input.

  If \dQuote{dataformat} is \dQuote{split}, the \dQuote{$numeric} slot of the value returned by the retrafo function
  object may also be a \code{matrix}. If \dQuote{dataformat} is \dQuote{numeric}, the returned object may also be a
  matrix.}

\item{dataformat.factor.with.ordered}{[\code{logical(1)}]\cr
Whether to treat \code{ordered} typed features as \code{factor} typed features. This affects how \code{dataformat} is handled, and only
has an effect if \code{dataformat} is \dQuote{split} or \dQuote{factor}.}

\item{export.params}{[\code{logical(1)} | \code{character}]\cr
Indicates which CPO parameters are exported by default. Exported parameters can be changed after construction using \code{\link{setHyperPars}},
but exporting too many parameters may lead to messy parameter sets if many CPOs are combined. This can be overridden on construction.
If this is a \code{logical(1)}, \code{TRUE} exports all parameters, \code{FALSE} to exports no parameters. It may also be a \code{character},
indicating the names of parameters to be exported. Default is \code{TRUE}.}

\item{fix.factors}{[\code{logical(1)}]\cr
Whether to constrain factor levels of new data to the levels of training data, for each factorial or ordered column. If new data contains
factors that were not present in training data, the values are set to \code{NA}. Default is \code{FALSE}.}

\item{properties}{[\code{character}]\cr
The kind if data that the CPO will be able to handle. This can be one or many of: \dQuote{numerics},
\dQuote{factors}, \dQuote{ordered}, \dQuote{missings}.
There should be a bias towards including properties. If a property is absent, the preproc
operator will reject the data. If an operation e.g. only works on numeric columns that have no
missings (like PCA), it is recommended to give all properties, ignore the columns that
are not numeric (using \dQuote{dataformat} = \dQuote{split}), and giving an error when
there are missings in the numeric columns (since missings in factorial features are not a problem).
Defaults to the maximal set.}

\item{properties.adding}{[\code{character}]\cr
Can be one or many of the same values as \dQuote{properties} for Feature Operation CPOs, and one or many of the same values as \dQuote{properties.target}
for Target Operation CPOs. These properties get added to a Learner (or CPO) coming after / behind this CPO. When a CPO imputes missing values, for example,
this should be \dQuote{missings}. This must be a subset of \dQuote{properties} or \dQuote{properties.target}. Default is
\code{character(0)}.}

\item{properties.needed}{[\code{character}]\cr
Can be one or many of the same values as \dQuote{properties} for Feature Operation CPOs,
and one or many of the same values as \dQuote{properties.target}. These properties are required
from a Learner (or CPO) coming after / behind this CPO. E.g., when a CPO converts factors to
numerics, this should be \dQuote{numerics} (and \dQuote{properties.adding} should be \dQuote{factors}).
Default is \code{character(0)}.}

\item{properties.target}{[\code{character}]\cr
  For Feature Operation CPOs, this can be one or many of \dQuote{cluster}, \dQuote{classif}, \dQuote{multilabel}, \dQuote{regr}, \dQuote{surv},
  \dQuote{oneclass}, \dQuote{twoclass}, \dQuote{multiclass}. Just as \code{properties}, it
  indicates what kind of data a CPO can work with. Data given as data.frame needs the \dQuote{cluster} property. Default is the maximal set.

  For Target Operation CPOs, this should only be given if the CPO operates on classification tasks. It must then be a subset of \dQuote{oneclass},
  \dQuote{twoclass}, or \dQuote{multiclass}. Otherwise, it should be \code{character(0)}. Default is \code{character(0)}.}

\item{packages}{[\code{character}]\cr
Package(s) that should be loaded when the CPO is constructed. This gives the user an early error if
a package required for the CPO is not available on his system, or can not be loaded. Default is \code{character(0)}.}

\item{cpo.trafo}{[\code{function}]\cr
This is a function which must have the parameters \dQuote{data} and \dQuote{target},
as well as the parameters specified in \dQuote{par.set}. (Alternatively,
the function may have a dotdotdot argument). This is a constructor function which must return a \dQuote{retrafo} function which
modifies data. This retrafo function must have exactly one argument--the (new) data--and return the modified data. The format
of the argument, and of the return value of the retrafo function, depends on the value of the \code{dataformat} parameter.}

\item{cpo.retrafo}{[\code{language} | \code{function}]\cr
Similarly to \dQuote{cpo.trafo}, this is either a function, the function body in curly braces (preferred), or \code{NULL}.
If this is not \code{NULL}, this function must have the same arguments as \code{cpo.trafo}, with the exception that
the \dQuote{target} argument is replaced by a \dQuote{control} argument, which will be
the value created in the \dQuote{cpo.trafo} run. It gets its input data in the same format as
\dQuote{cpo.trafo}, with the exception that if \dQuote{.dataformat} is \dQuote{task}, it gets a
\dQuote{data.frame} as if \dQuote{.dataformat} were \dQuote{df.all}. This function must similarly return an
object in the same format as it received as input.}
}
\description{
\code{makeCPO} creates a \emph{Feature Operation} \code{\link{CPOConstructor}}, i.e. a constructor for a \code{\link{CPO}} that will
operate on feature columns. \code{makeCPOTargetOp} creates a \emph{Target Operation} \code{\link{CPOConstructor}}, which
creates \code{\link{CPO}}s that operate on the target column. \code{makeCPORetrafoless} creates a \emph{Retrafoless} \code{\link{CPOConstructor}},
which creates \code{\link{CPO}}s that may operate on both feature and target columns, but have no retrafo operation. See \link{OperatingTypes} for further
details on the distinction of these.
}
\section{CPO Internals}{

The mlrCPO package offers a powerful framework for handling the tasks necessary for preprocessing, so that the user, when creating custom CPOs,
can focus on the actual data transformations to perform. It is, however, useful to understand \emph{what} it is that the framework does, and how
the process can be influenced by the user during CPO definition or application. Aspects of preprocessing that the user needs to influence are:
\describe{
  \item{\strong{Operating Type}}{
    The core of preprocessing is the actual transformation being performed. In the most general sense, there are three points in a machine
    learning pipeline that preprocessing can influence.
    \enumerate{
      \item Transformation of training data \emph{before model fitting}, done in mlr using \code{\link[mlr]{train}}. In the CPO framework
        (\emph{when not using a \code{\link{CPOLearner}} which makes all of these steps transparent to the user}), this is
        done by a \code{\link{CPO}}.
      \item transformation of new validation or prediction data that is given to the fitted model for \emph{prediction}, done using
        \code{\link[stats]{predict}}. This is done by a \code{\link{CPORetrafo}} retrieved using \code{\link{retrafo}} from the result of step 1.
      \item transformation of the predictions made to invert the transformation of the target values done in step 1, which is done using
        the \code{\link{CPOInverter}} retrieved using \code{\link{inverter}} from the result of step 2.
    }
    The framework poses restrictions on primitive (i.e. not compound using \code{\link{composeCPO}}) \code{\link{CPO}}s to simplify internal
    operation: A \code{\link{CPO}} may be one of three \link{OperatingTypes} (see there). The \emph{Feature Operation} \code{\link{CPO}} does not
    transform target columns and hence only needs to be involved in steps 1 and 2. The \emph{Target Operation} \code{\link{CPO}} only transforms
    target columns, and therefore only concerns itself with steps 1 and 3. A \emph{Retrafoless} \code{\link{CPO}} may change both feature and
    target columns, but may not perform a retrafo \emph{or} inverter operation (and is therefore only concerned with step 1). Note that this
    is effectively a restriction on what kind of transformation a Retrafoless CPO may perform: it must not be a transformation of the data
    or target \emph{space}, it may only act or subtract points within this space.

    The Operating Type of a \code{\link{CPO}} is ultimately dependent on the function that was used to create the \code{\link{CPOConstructor}}:
    \code{makeCPO}, \code{makeCPOTargetOp}, or \code{makeCPORetrafoless}.}
  \item{\strong{Data Transformation}}{
    At the core of a CPO is the modification of data it performs. The transformation of each row, during training \emph{and} prediction, should
    happen in the same way, and it may only depend on the entirety of the \emph{training} data--i.e. the value of a data row in a prediction
    data set may not influence the transformation of a different prediction data row. This property is ensured by splitting the transformation
    into two functions: One function that collects all relevant information from the training data (called \code{train}), and one that transforms
    given data, using this collected information and (\emph{potentially new, unseen}) data to be transformed (called \code{retrafo}). The \code{retrafo}
    function should handle all data as if it were prediction data and unrelated to the data given to \code{train}.

    Internally, when a \code{\link{CPO}} gets applied to a data set using \code{\link{applyCPO}}, the \code{train} function is called, and the
    resulting control object is used for a subsequent \code{retrafo} call which transforms the data. Before the result is given back from the
    \code{\link{applyCPO}} call, the control object is used to create a \code{\link{CPORetrafo}} object and a \code{\link{CPOInverter}} object,
    which are attached to the result as attributes.

    When a \code{\link{CPORetrafo}} is then applied to new prediction data, the control object previously returned by \code{train} is given,
    combined with this \emph{new} data, to another \code{retrafo} call that performs the new transformation.

    Note that the \code{*Extended} functions optionally offer different semantics for the given functions.}
  \item{\strong{\code{train}-\code{retrafo} information transfer}}{
    One possibility to transfer information from \code{train} to \code{retrafo} is to have \code{train} return a control object (a \code{\link[base]{list}})
    that is then given to \code{retrafo}. The CPO is then called an \emph{object based} CPO.

    Another possibility is to not give a \code{retrafo}
    function (set it to \code{NULL} in the \code{makeCPO} call) and have \code{train} instead return a \emph{function} instead. This function is then
    used as the \code{retrafo} function, and should have access to all relevant information about the training data as a closure. This is called
    \emph{functional} CPO. To save memory, the actual data given to \code{train} is removed from the environment of its return value in this case
    (i.e. the environment of the retrafo function). This means the retrafo function may not reference a \dQuote{\code{data}} variable.}
  \item{\strong{Hyperparameters}}{
    The action performed by a CPO may be influenced using \emph{hyperparameters}, during its construction as well as afterwards (then using
    \code{\link[mlr]{setHyperPars}}). Hyperparameters must be specified as a \code{\link[ParamHelpers:makeParamSet]{ParamSet}} and given as argument \code{par.set}.
    Default values for each parameter may be specified in this \code{\link[ParamHelpers:makeParamSet]{ParamSet}} or optionally as another argument \code{par.vals}.

    Hyperparameters given are made part of the \code{\link{CPOConstructor}} function and can thus be given during construction.
    Parameter default values function as the default values for the \code{\link{CPOConstructor}} function parameters (which are thus made optional function
    parameters of the \code{\link{CPOConstructor}} function). The CPO framework handles storage and changing of hyperparameter values.
    When the \code{train} and \code{retrafo} functions are called to transform data, the hyperparameter values are given to them as arguments, so
    \code{train} and \code{retrafo} functions must be able to accept these parameters, either directly, or with a \code{...} argument.

    Note that with \emph{functional} \code{\link{CPO}}s, the \code{retrafo} function does not take hyperparameter arguments (and instead can usually
    refer to them by its environment).

    Hyperparameters may be \emph{exported} (or not), thus making them available for \code{\link[mlr]{setHyperPars}}. Not exporting a parameter
    has advantage that it does not clutter the \code{\link[ParamHelpers:makeParamSet]{ParamSet}} of a big \code{\link{CPO}} or \code{\link{CPOLearner}} pipeline with
    many hyperparameters. Which hyperparameters are exported is chosen during the constructing call of a \code{\link{CPOConstructor}}, but the default
    exported hyperparameters can be chosen with the \code{export.params} parameter.}
  \item{\strong{Properties}}{
    Similarly to \code{\link[mlr:makeLearner]{Learner}}s, \code{\link{CPO}}s may specify what kind of data they are and are not able to handle. This is done by
    specifying \code{properties.*} arguments. The names of possible properties are the same as possible \code{\link[mlr]{LearnerProperties}}, but since
    \code{\link{CPO}}s mostly concern themselves with data, only the properties indicating column and task types are relevant.

    For each \code{\link{CPO}} one must specify
    \enumerate{
      \item which kind of data does the \code{\link{CPO}} handle,
      \item which kind of data must the \code{\link{CPO}} or \code{\link[mlr:makeLearner]{Learner}} be able to handle that comes \emph{after}
        the given \code{\link{CPO}}, and
      \item which kind of data handling capability does the given \code{\link{CPO}} \emph{add} to a following
        \code{\link{CPO}} or \code{\link[mlr:makeLearner]{Learner}} if coming before it in a pipeline.
    }
    The specification of (1) is done with \code{properties.data} and \code{properties.target}, (2) is specified using \code{properties.needed}, and
    (3) is specified using \code{properties.adding}. Internally, \code{properties.data} and \code{properties.target} are concatenated and treated as
    one vector, they are specified separately in \code{makeCPO} etc. for convenience reasons. See \code{\link{CPOProperties}} for details.}
  \item{\strong{Data Format}}{
    EXPLANATION # TODO}
  \item{\strong{ID}}{
    EXPLANATION # TODO}
  \item{\strong{Packages}}{
    EXPLANATION # TODO}
}

\code{makeCPO}, \code{makeCPOTargetOp} and \code{\link{makeCPORetrafoless}} have a comparatively easy user-interface; for more advanced use-cases and
interesting shortcuts, use \code{\link{makeCPOExtended}}, \code{\link{makeCPOTargetOpExtended}}, \code{\link{makeCPORetrafolessExtended}}.
}

\examples{
# an example constant feature remover CPO
constFeatRem = makeCPO("constFeatRem",
 dataformat = "df.features",
 cpo.trafo = function(data, target) {
   names(Filter(function(x) {  # names of columns to keep
       length(unique(x)) > 1
     }, data))
   }, cpo.retrafo = function(data, control) {
   data[control]
 })
# alternatively:
constFeatRem = makeCPO("constFeatRem",
  dataformat = "df.features",
  cpo.trafo = function(data, target) {
    cols.keep = names(Filter(function(x) {
        length(unique(x)) > 1
      }, data))
    # the following function will do both the trafo and retrafo
    result = function(data) {
      data[cols.keep]
    }
    result
  }, cpo.retrafo = NULL)
}
\seealso{
Other CPO: \code{\link{CPOImputer}},
  \code{\link{cpoApplyFun}}, \code{\link{cpoAsNumeric}},
  \code{\link{cpoCase}}, \code{\link{cpoCollapseFact}},
  \code{\link{cpoDropConstants}},
  \code{\link{cpoDummyEncode}},
  \code{\link{cpoFilterFeatures}},
  \code{\link{cpoFixFactors}},
  \code{\link{cpoImpactEncodeClassif}},
  \code{\link{cpoImpactEncodeRegr}},
  \code{\link{cpoImpute}},
  \code{\link{cpoMissingIndicators}},
  \code{\link{cpoModelMatrix}}, \code{\link{cpoMultiplex}},
  \code{\link{cpoPca}}, \code{\link{cpoProbEncode}},
  \code{\link{cpoQuantileBinNumerics}},
  \code{\link{cpoScaleMaxAbs}},
  \code{\link{cpoScaleRange}}, \code{\link{cpoScale}},
  \code{\link{cpoSelect}}, \code{\link{cpoSpatialSign}},
  \code{\link{cpoWrap}}, \code{\link{makeCPOExtended}}
}
